experiment:
  name: "SceneSegLite"    # name of the experiment, used for logging and checkpointing
  output_dir: "runs/training/SceneSegLite/"
  seed: 42
  device: "cuda"    # "cuda", "cuda:0", or "cpu"
  wandb:
    enabled: true
    project_name: "SceneSegLite"     #it is fixed from the account

checkpoint:
  load_from:         # path to checkpoint to load before training
  strict_load:      # whether to strictly enforce that the keys in state_dict match the keys returned by the model's state_dict function

dataset:
  training_sets: ["acdc","mapillary","muses","bdd100k","cityscapes"]    # <--- LIST OF DATASETS TO USE FOR TRAIN

  acdc_root: "/home/sergey/DEV/AI/datasets/acdc"
  mapillary_root: "/home/sergey/DEV/AI/datasets/mapillary"
  muses_root: "/home/sergey/DEV/AI/datasets/MUSES"
  bdd100k_root: "/home/sergey/DEV/AI/datasets/BDD100K"
  cityscapes_root: "/home/sergey/DEV/AI/datasets/cityscapes"

  #mapillary validation set has various images width -> non batchable -> very very slow -> exclude from validation
  validation_sets: ["acdc","muses","bdd100k","cityscapes"]    # <--- LIST OF DATASETS TO USE FOR VALIDATION


  #augmentations settings for all datasets
  augmentations:
    normalize:
      enabled: true
      mean: [0.485, 0.456, 0.406]   # imagenet mean, RGB ORDER  
      std: [0.229, 0.224, 0.225]    # imagenet std, RGB ORDER

    rescaling:
      enabled: true
      mode: "random_crop"    # fixed_resize | random_crop


      width: 1024  
      height: 512

      #for random cropping
      scale_range: [0.5, 2.0]   # min and max scale for random cropping

    # Horizontal flip
    flip_prob: 0.5

    # Optional random grid shuffle
    random_grid_shuffle:
      enabled: false        # set true if you want it
      grid: [1, 2]
      prob: 0.25

    # Noise settings
    noise:
      profile: "moderate"   # none | moderate | heavy | roadwork
      prob: 0.5             # probability noise is applied


dataloader:
  batch_size: 8             # how many samples per optimization step
  num_workers: 6            # how many workers for data loading
  pin_memory: true          # pin memory for dataloader
  persistent_workers: true  # keep workers alive between epochs
  drop_last: true           # drop last incomplete batch
  prefetch_factor: 2        # number of batches to prefetch
  shuffle_train: true       # shuffle training data (random order, but complete every sample before epoch)
  shuffle_val: false        # do not shuffle validation data

training:
  mode: "steps"        # "epoch" or "steps" 
  max_epochs: 200       # used if mode == "epoch"
  max_steps: 160000     # used if mode == "steps". step = optimization step (so affected by batch size and grad accum)
  grad_accum_steps: 1

  validation:
    mode: "steps"        # "epoch" or "steps"
    every_n_epochs: 1    # used if mode == "epoch"
    every_n_steps: 5000    # used if mode == "steps"

  logging:
    log_every_steps: 50    # step = optimization step (so affected by batch size and grad accum)
  
  save_best: true           # save best mIoU
  save_last: true           # always save last

optimizer:
  type: "adamw"            # "sgd" or "adamw"
  lr: 1.0e-4              #ADAMW: default 1.0e-4 | SGD: default 1.0e-2

  #shared among optimizers
  weight_decay: 1.0e-2    #adamw: default 1.0e-2 | sgd: default 1.0e-4

  #sgd parameters
  momentum: 0.9           #default

  #adamw parameters
  betas: [0.9, 0.999]     #default

scheduler:
  type: "warmup_cosine"              # "none" or "step", "cosine", "warmup_cosine", "poly"
  
  #for "step" scheduler 
  step_size: 30           # used if type == "step"
  gamma: 0.1              # used if type == "step"
  
  #for "warmup_cosine" scheduler and "cosine" scheduler
  warmup_steps: 1000      # used if type == "warmup_cosine". Note: steps = OPTIMIZATION STEPS (batch_size * iterations)
  min_lr: 1.0e-6          # used if type == "warmup_cosine"

loss:
  type: "cross_entropy"
  ignore_index: 255

  num_classes: 19
  class_names:
    0: "road"
    1: "sidewalk"
    2: "building"
    3: "wall"
    4: "fence"
    5: "pole"
    6: "traffic_light"
    7: "traffic_sign"
    8: "vegetation"
    9: "terrain"
    10: "sky"
    11: "person"
    12: "rider"
    13: "car"
    14: "truck"
    15: "bus"
    16: "train"
    17: "motorcycle"
    18: "bicycle"

  #weighted loss : enable or not
  apply_weights:
    enabled: false
    
    #bdd100k, acdc, muses, mapillary averaged weights
    values: [4.573028, 15.455213, 6.470042, 33.704417, 27.493553, 30.994083, 46.015051, 38.803442, 5.883573, 26.579644, 3.594793, 43.808040, 49.085101, 18.574798, 42.354083, 44.287061, 45.432288, 49.032655, 48.829367]




network:
  model: "deeplabv3plus"    #deeplabv3plus | fcn | unetplusplus
  type: "custom"    #standard uses the smp.deeplabv3plus architecture, custom uses my own integrated implementation (used for loading some weights customly)
  

  #load a pretrained model to use as backbone (also as decoder if specified)
  pretrained_model_path:  #"/home/sergey/DEV/AI/AEI/runs/training/segmentation/dlv3plus_efficientnetb1_v2/checkpoints/best_mIoU.pth"     # path to a pretrained model to use as backbone (overrides 'pretrained' flag)

  backbone:
    type: "efficientnet_b1"  # e.g., "resnet50", "efficientnet_b0", etc.
    pretrained: true         # whether to use ImageNet pre-trained weights
    encoder_depth: 5      #the encoder features that will be used in decoder (5 means the last stage before 1x1conv, 4 means the one before that, etc.)

    encoder_partial_load: false      # whether to partially load encoder weights from the pretrained model specified in pretrained_model_path
    encoder_partial_depth: 4        # how many stages to load if encoder_partial_load is
    
    output_stride: 16        # 8 or 16

    #if pretrained model is used. Ignore the type and pretrained flags
    load_encoder: false             # whether to load encoder weights from the pretrained model specified in pretrained_model_path
    freeze_encoder: false            # whether to freeze backbone weights during training. It freezes until the encoder_partial_depth if encoder_partial_load is true

  bottleneck:
    #used to better map the backbone features to the decoder input
    type : "none"   # "none" | "fcn" | "fcn_cbam" | "fcn_skip" | "fcn_skip_cbam"
    #number of channels is the same of the backbone output channels

  decoder:
    #for deeplabv3plus
    aspp_dilations: [12, 24, 36]   #dilation rates for ASPP module
    deeplabv3plus_decoder_channels: 64        #number of channels in decoder

    load_decoder: false    # whether to load decoder weights from the pretrained model specified in backbone.pretrained_model_path
    freeze_decoder: false    # whether to freeze decoder weights during training

  head:
    head_activation: null
    head_depth: 1
    head_mid_channels: None
    head_upsampling: 4
    head_kernel_size: 3

  output_channels: 19